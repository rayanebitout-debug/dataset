{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayanebitout-debug/dataset/blob/main/Mini_Projet_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7r1-SpN6KpX",
        "outputId": "c0cceca5-037f-4661-e0b6-0c917390be7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Excel export√©: /content/resultats/gainesville_analysis.xlsx\n",
            "\n",
            "============================================================\n",
            "ANALYSE TERMIN√âE AVEC SUCC√àS\n",
            "============================================================\n",
            "\n",
            "üìÇ FICHIERS PRODUITS:\n",
            "------------------------------\n",
            "  ‚Ä¢ rapport_detaille.txt (3.4 KB)\n",
            "  ‚Ä¢ rapport_analyse.txt (1.0 KB)\n",
            "  ‚Ä¢ Gainesville_clean.csv (35119.5 KB)\n",
            "  ‚Ä¢ correlation_matrix.png (324.5 KB)\n",
            "  ‚Ä¢ gainesville_data.json (27.8 KB)\n",
            "  ‚Ä¢ electric_eui_distribution.png (142.6 KB)\n",
            "  ‚Ä¢ gainesville.db (33944.0 KB)\n",
            "  ‚Ä¢ gainesville_analysis.xlsx (14128.3 KB)\n",
            "\n",
            "üéØ Nombre total de fichiers: 8\n",
            "üìÅ Tous les fichiers sont disponibles dans le dossier /content/resultats/\n",
            "\n",
            "============================================================\n",
            "MINI-PROJET R√âALIS√â PAR NOTRE GROUPE D'√âTUDIANTS\n",
            "Analyse Automatique de Donn√©es de Recherche\n",
            "Sciences et Technologies (ST)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print('======================================================================================')\n",
        "print('MINI-PROJET DE LA MATIERE FTP')\n",
        "print(\"Groupe d'√©tudiants en Architecture :\\n\"\n",
        "      \"- SAOU Youssra\\n\"\n",
        "      \"- OUADIA Imane\\n\"\n",
        "      \"- BITOUT Rayane\\n\"\n",
        "      \"- TATAH Lina\")\n",
        "print('======================================================================================')\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 0 : Installation des biblioth√®ques n√©cessaires\n",
        "# ------------------------------------------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"√âTAPE 0 : Installation des biblioth√®ques n√©cessaires\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "!pip install seaborn -q\n",
        "!pip install patool -q  # Pour g√©rer les fichiers .rar\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 1 : Importation des biblioth√®ques\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 1 : Importation des biblioth√®ques\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import patoolib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 2 : Configuration de l'environnement\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 2 : Configuration de l'environnement\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "BASE_DIR = \"/content\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"resultats\")\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ R√©pertoire donn√©es: {DATA_DIR}\")\n",
        "print(f\"üìÅ R√©pertoire r√©sultats: {RESULTS_DIR}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 3 : T√©l√©chargement du dataset\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 3 : T√©l√©chargement du dataset\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "RAR_PATH = os.path.join(DATA_DIR, \"Gainesville.rar\")\n",
        "DATASET_URL = \"https://github.com/rayanebitout-debug/dataset/raw/main/Gainesville.rar\"\n",
        "\n",
        "print(f\"üîó URL du dataset: {DATASET_URL}\")\n",
        "\n",
        "# Supprimer l'ancien fichier s'il existe\n",
        "if os.path.exists(RAR_PATH):\n",
        "    os.remove(RAR_PATH)\n",
        "\n",
        "# T√©l√©charger le dataset\n",
        "!wget --no-check-certificate -q --show-progress \"$DATASET_URL\" -O \"$RAR_PATH\"\n",
        "\n",
        "# V√©rifier le t√©l√©chargement\n",
        "if not os.path.exists(RAR_PATH):\n",
        "    raise RuntimeError(\"‚ùå √âchec du t√©l√©chargement\")\n",
        "\n",
        "file_size = os.path.getsize(RAR_PATH)\n",
        "print(f\"üìä Taille du fichier: {file_size} octets\")\n",
        "print(\"‚úÖ Dataset t√©l√©charg√© avec succ√®s\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 4 : D√©compression du fichier\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 4 : D√©compression du fichier\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    patoolib.extract_archive(RAR_PATH, outdir=DATA_DIR)\n",
        "    print(\"‚úÖ Fichier RAR extrait avec succ√®s\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Erreur avec patool: {e}\")\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(RAR_PATH, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DATA_DIR)\n",
        "            print(\"‚úÖ Extraction avec zipfile r√©ussie\")\n",
        "    except:\n",
        "        raise RuntimeError(\"‚ùå Impossible d'extraire le fichier\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 5 : Lecture des donn√©es\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 5 : Lecture des donn√©es\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Rechercher les fichiers CSV\n",
        "csv_files = []\n",
        "for root, dirs, files in os.walk(DATA_DIR):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(\".csv\"):\n",
        "            csv_files.append(os.path.join(root, f))\n",
        "\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(\"‚ùå Aucun fichier CSV trouv√©\")\n",
        "\n",
        "csv_path = csv_files[0]\n",
        "print(f\"üìÑ Fichier CSV trouv√©: {csv_path}\")\n",
        "\n",
        "# Essayer diff√©rents encodages\n",
        "encodings = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']\n",
        "df = None\n",
        "\n",
        "for encoding in encodings:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, encoding=encoding)\n",
        "        print(f\"‚úÖ Lecture r√©ussie avec l'encodage: {encoding}\")\n",
        "        break\n",
        "    except UnicodeDecodeError:\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erreur avec {encoding}: {str(e)[:50]}\")\n",
        "\n",
        "if df is None:\n",
        "    df = pd.read_csv(csv_path, encoding='latin-1', engine='python', on_bad_lines='skip')\n",
        "    print(\"‚ö†Ô∏è Lecture avec param√®tres de secours\")\n",
        "\n",
        "print(\"üìä Aper√ßu des donn√©es charg√©es:\")\n",
        "print(df.head())\n",
        "print(f\"\\nüìà Dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
        "df_original = df.copy()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 6 : Nettoyage des donn√©es\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 6 : Nettoyage des donn√©es\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üßπ Remplacement des valeurs manquantes...\")\n",
        "missing_values = ['No Value', 'Unknown', 'N/A', 'NA', '', '-', '--', 'null', 'NULL', 'NaN', 'nan', 'None', 'NONE']\n",
        "df = df.replace(missing_values, np.nan)\n",
        "\n",
        "print(\"üî¢ Conversion des colonnes num√©riques...\")\n",
        "potential_numeric_cols = [\n",
        "    'electric_eui', 'fuel_eui', 'site_eui', 'source_eui',\n",
        "    'ghg_emissions_int', 'number_of_people', 'occupant_density',\n",
        "    'operating_hours', 'energy_star_rating', 'leed_score',\n",
        "    'total_ghg_emissions', 'electricity_use', 'natural_gas_use',\n",
        "    'total_energy_use', 'building_area', 'year_built'\n",
        "]\n",
        "\n",
        "for col in potential_numeric_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        non_null = df[col].notna().sum()\n",
        "        if non_null > 0:\n",
        "            print(f\"  ‚úì {col}: {non_null} valeurs non-nulles\")\n",
        "\n",
        "print(\"üìâ Suppression des colonnes avec trop de valeurs manquantes...\")\n",
        "initial_cols = df.shape[1]\n",
        "df_cleaned = df.loc[:, df.isna().mean() < 0.9]\n",
        "df = df_cleaned\n",
        "removed_cols = initial_cols - df.shape[1]\n",
        "print(f\"  ‚úì {removed_cols} colonnes supprim√©es\")\n",
        "\n",
        "print(\"üóëÔ∏è Suppression des lignes enti√®rement vides...\")\n",
        "initial_rows = df.shape[0]\n",
        "df = df.dropna(how='all')\n",
        "removed_rows = initial_rows - df.shape[0]\n",
        "print(f\"  ‚úì {removed_rows} lignes supprim√©es\")\n",
        "\n",
        "clean_csv = os.path.join(RESULTS_DIR, \"Gainesville_clean.csv\")\n",
        "df.to_csv(clean_csv, index=False, encoding='utf-8')\n",
        "print(f\"üíæ Donn√©es nettoy√©es sauvegard√©es: {clean_csv}\")\n",
        "print(f\"üìä Nouvelles dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 7 : Stockage des r√©sultats en base de donn√©es\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 7 : Stockage des r√©sultats en base de donn√©es\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "db_path = os.path.join(RESULTS_DIR, \"gainesville.db\")\n",
        "conn = sqlite3.connect(db_path)\n",
        "df.to_sql(\"gainesville_energy\", conn, if_exists=\"replace\", index=False)\n",
        "conn.close()\n",
        "\n",
        "print(f\"üóÑÔ∏è Base de donn√©es cr√©√©e: {db_path}\")\n",
        "print(f\"üìä Table 'gainesville_energy' avec {df.shape[0]} enregistrements\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 8 : Visualisation des donn√©es\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 8 : Visualisation des donn√©es\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Distribution de l'EUI √©lectrique\n",
        "if 'electric_eui' in df.columns and df['electric_eui'].notna().sum() > 0:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(df['electric_eui'].dropna(), bins=40, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "    plt.title(\"Distribution Electric EUI\", fontsize=14)\n",
        "    plt.xlabel(\"kWh/m¬≤\")\n",
        "    plt.ylabel(\"Nombre de b√¢timents\")\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    df['electric_eui'].dropna().plot(kind='box')\n",
        "    plt.title(\"Boxplot Electric EUI\", fontsize=14)\n",
        "    plt.ylabel(\"kWh/m¬≤\")\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, \"electric_eui_distribution.png\"), dpi=300)\n",
        "    plt.show()\n",
        "    print(\"‚úÖ Graphique Electric EUI g√©n√©r√©\")\n",
        "\n",
        "# 2. Matrice de corr√©lation\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "if numeric_df.shape[1] > 2:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    correlation = numeric_df.corr()\n",
        "    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "    plt.title(\"Matrice de corr√©lation\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, \"correlation_matrix.png\"), dpi=300)\n",
        "    plt.show()\n",
        "    print(\"‚úÖ Matrice de corr√©lation g√©n√©r√©e\")\n",
        "\n",
        "# 3. Top 10 des b√¢timents par consommation\n",
        "if 'electric_eui' in df.columns and 'building_name' in df.columns:\n",
        "    top_buildings = df.dropna(subset=['electric_eui']).nlargest(10, 'electric_eui')\n",
        "    if len(top_buildings) > 0:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(range(len(top_buildings)), top_buildings['electric_eui'])\n",
        "        plt.yticks(range(len(top_buildings)), top_buildings['building_name'])\n",
        "        plt.xlabel('Electric EUI (kWh/m¬≤)')\n",
        "        plt.title('Top 10 b√¢timents par consommation √©lectrique')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(RESULTS_DIR, \"top_buildings_eui.png\"), dpi=300)\n",
        "        plt.show()\n",
        "        print(\"‚úÖ Graphique top 10 b√¢timents g√©n√©r√©\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 9 : G√©n√©ration du rapport d√©taill√©\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 9 : G√©n√©ration du rapport d√©taill√©\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìä RAPPORT D'ANALYSE - DONN√âES √âNERG√âTIQUES GAINESVILLE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"üìÖ Date d'analyse: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")\n",
        "print(f\"üìÅ Source: {os.path.basename(csv_path)}\")\n",
        "print(f\"üìà Donn√©es initiales: {df_original.shape[0]} lignes, {df_original.shape[1]} colonnes\")\n",
        "print(f\"üßπ Donn√©es apr√®s nettoyage: {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
        "print(f\"üìâ Donn√©es supprim√©es: {df_original.shape[0] - df.shape[0]} lignes\")\n",
        "\n",
        "print(\"\\nüìã STATISTIQUES PRINCIPALES:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 0:\n",
        "    print(f\"Colonnes num√©riques: {len(numeric_cols)}\")\n",
        "    for col in numeric_cols[:3]:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"  ‚Ä¢ Moyenne: {df[col].mean():.2f}\")\n",
        "        print(f\"  ‚Ä¢ M√©diane: {df[col].median():.2f}\")\n",
        "        print(f\"  ‚Ä¢ √âcart-type: {df[col].std():.2f}\")\n",
        "\n",
        "    if 'electric_eui' in df.columns:\n",
        "        print(f\"\\n‚ö° Consommation √©lectrique moyenne: {df['electric_eui'].mean():.1f} kWh/m¬≤\")\n",
        "\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(cat_cols) > 0:\n",
        "    print(f\"\\nColonnes cat√©gorielles: {len(cat_cols)}\")\n",
        "\n",
        "# Sauvegarde du rapport dans un fichier\n",
        "report_path = os.path.join(RESULTS_DIR, \"rapport_analyse.txt\")\n",
        "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"RAPPORT D'ANALYSE - DONN√âES √âNERG√âTIQUES GAINESVILLE\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "    f.write(f\"Date d'analyse: {datetime.now().strftime('%d/%m/%Y %H:%M')}\\n\")\n",
        "    f.write(f\"Donn√©es initiales: {df_original.shape[0]} lignes √ó {df_original.shape[1]} colonnes\\n\")\n",
        "    f.write(f\"Donn√©es nettoy√©es: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\\n\\n\")\n",
        "\n",
        "    f.write(\"R√âSUM√â STATISTIQUE:\\n\")\n",
        "    for col in numeric_cols:\n",
        "        f.write(f\"\\n{col}:\\n\")\n",
        "        f.write(f\"  ‚Ä¢ Non-null: {df[col].notna().sum()}/{len(df)}\\n\")\n",
        "        if df[col].notna().sum() > 0:\n",
        "            f.write(f\"  ‚Ä¢ Moyenne: {df[col].mean():.2f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ M√©diane: {df[col].median():.2f}\\n\")\n",
        "\n",
        "print(f\"\\nüíæ Rapport sauvegard√©: {report_path}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# √âTAPE 10 : Exportation des r√©sultats dans diff√©rents formats\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"√âTAPE 10 : Exportation des r√©sultats\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Export JSON\n",
        "json_path = os.path.join(RESULTS_DIR, \"gainesville_data.json\")\n",
        "df.head(50).to_json(json_path, orient='records', indent=2)\n",
        "print(f\"üìÑ JSON export√©: {json_path}\")\n",
        "\n",
        "# Export Excel\n",
        "excel_path = os.path.join(RESULTS_DIR, \"gainesville_analysis.xlsx\")\n",
        "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
        "    df.to_excel(writer, sheet_name='Donn√©es nettoy√©es', index=False)\n",
        "\n",
        "    summary_df = pd.DataFrame({\n",
        "        'Colonne': df.columns,\n",
        "        'Type': df.dtypes.astype(str),\n",
        "        'Non-Null': df.notna().sum().values,\n",
        "        'Null': df.isna().sum().values,\n",
        "        '% Null': (df.isna().mean() * 100).round(2).values\n",
        "    })\n",
        "    summary_df.to_excel(writer, sheet_name='R√©sum√©', index=False)\n",
        "\n",
        "print(f\"üìä Excel export√©: {excel_path}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FIN : R√©sum√© des fichiers produits\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANALYSE TERMIN√âE AVEC SUCC√àS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìÇ FICHIERS PRODUITS:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "files_produced = []\n",
        "for file in os.listdir(RESULTS_DIR):\n",
        "    file_path = os.path.join(RESULTS_DIR, file)\n",
        "    size_kb = os.path.getsize(file_path) / 1024\n",
        "    files_produced.append((file, size_kb))\n",
        "    print(f\"  ‚Ä¢ {file} ({size_kb:.1f} KB)\")\n",
        "\n",
        "print(f\"\\nüéØ Nombre total de fichiers: {len(files_produced)}\")\n",
        "print(\"üìÅ Tous les fichiers sont disponibles dans le dossier /content/resultats/\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MINI-PROJET R√âALIS√â PAR NOTRE GROUPE D'√âTUDIANTS\")\n",
        "print(\"Analyse Automatique de Donn√©es de Recherche\")\n",
        "print(\"Sciences et Technologies (ST)\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7x+tOYNKg/fxzI2m9Udhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}